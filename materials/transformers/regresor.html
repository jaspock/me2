<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Regresión logística | Juan Antonio Pérez-Ortiz</title> <meta name="author" content="Juan Antonio Pérez-Ortiz"> <meta name="description" content="Conociendo al hermano pequeño de las redes neuronales"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%92%AC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/me2/assets/css/main.css"> <link rel="canonical" href="https://jaspock.github.io/me2/materials/transformers/regresor"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/me2/assets/js/theme.js"></script> <script src="/me2/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/me2/"><span class="font-weight-bold">Juan Antonio </span>Pérez-Ortiz</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/me2/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/me2/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/me2/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/me2/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/me2/materials/">materials</a> </li> <li class="nav-item "> <a class="nav-link" href="/me2/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/me2/teaching/">teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/me2/repositories/">repositories</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Regresión logística</h1> <p class="post-description">Conociendo al hermano pequeño de las redes neuronales</p> </header> <article> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/me2/assets/img/transformers/book-blue-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/me2/assets/img/transformers/book-blue-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/me2/assets/img/transformers/book-blue-1400.webp"></source> <img src="/me2/assets/img/transformers/book-blue.png" class="img-fluid rounded z-depth-1" width="256px" height="256px" title="ai-generated image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p class="small-text">Nota: este capítulo es parte de la serie “<a href="../transformers">Un recorrido peso a peso por el transformer</a>”, donde se presenta una guía para aprender cómo funcionan las redes neuronales que procesan textos y cómo se programan.</p> <h2 id="regresores">Regresores</h2> <p><i class="fas fa-clock"></i> 3 horas</p> <p>Nuestros primeros pasos por el camino de baldosas amarillas nos llevan al hermano pequeño de la familia de redes neuronales: el regresor logístico, al que, en general, ni siquiera se considera una red neuronal. Por el camino, aprenderás muchos elementos del aprendizaje automático que luego seguirán aplicándose a modelos más complejos. Comienza, por tanto, con el capítulo “<a href="https://web.archive.org/web/20221218211150/https://web.stanford.edu/~jurafsky/slp3/5.pdf" rel="external nofollow noopener" target="_blank">Logistic Regression</a>”, <a href="https://web.archive.org/web/20221218211150/https://web.stanford.edu/~jurafsky/slp3/5.pdf" rel="external nofollow noopener" target="_blank"><i class="fas fa-file"></i></a> complementándolo con lo que se discute a continuación.</p> <p>Casi la totalidad del capítulo es muy relevante para nuestros propósitos al tratarse de un capítulo introductorio, pero puedes saltarte lo siguiente:</p> <ul> <li>La introducción que hay antes del apartado 5.1, ya que se basa en elementos de capítulos anteriores (clasificador bayesiano) que no has visto.</li> <li>El apartado 5.2.2 (“Other classification tasks and features”).</li> <li>El apartado 5.2.4 (“Choosing a classifier”).</li> <li>La sección 5.7 (“Regularization”).</li> <li>Por último, no es necesario que comprendas la sección 5.10 (“Advanced: Deriving the Gradient Equation”) antes de pasar a capítulos posteriores, pero es muy recomendable que seas capaz de derivar por ti mismo la función de pérdida más pronto que tarde. Cuando los modelos se vayan haciendo más complejos, obtener la derivada manualmente será una tarea ardua e innecesaria (porque librerías como PyTorch se encargarán de calcularla por nosotros), pero hacerlo ahora mejorará tu perspectiva del entrenamiento de redes neuronales.</li> </ul> <p>Este capítulo puede que resulte ser de los más complejos y el que ofrece una mayor curva de aprendizaje al aparecer en él un montón de elementos que quizás son nuevos para ti. A continuación, se matizan o enfatizan algunos de los conceptos más importantes de cada apartado.</p> <h2 id="anotaciones-al-libro">Anotaciones al libro</h2> <p>Es recomendable que estudies estos comentarios después de una primera lectura del capítulo y antes de la segunda lectura.</p> <h4 id="apartado-51">Apartado 5.1</h4> <p>Se introduce el concepto de producto escalar que será una piedra angular de todo lo que está por venir. Si recuerdas cómo se hacía el producto de matrices (que aparecerá numerosas veces más adelante), observarás que este consiste en una serie de cálculos de productos escalares. El sesgo (<em>bias</em>) es importante en algunos problemas porque permite desplazar las fronteras de decisión como demostraremos más adelante. Observa que no linealidad de la exponenciación de la función sigmoide <em>encoge</em> las diferencias entre los valores de salida de la función según nos alejamos del origen, ya que \(\sigma(2)-\sigma(0) &gt;&gt;&gt; \sigma(4)-\sigma(2)\). Por otro lado, no es necesario que hagas la demostración analítica, pero sí que observes gráficamente que \(1 - \sigma(x) = \sigma(-x)\); esta propiedad nos permitirá simplificar algunas ecuaciones. Finalmente, observa que por ahora la función \(\sigma\) se está aplicando a un escalar, pero más adelante se aplicará a un vector o incluso a un tensor de cualquier número de dimensiones. En este caso, la función se aplica elemento a elemento, es decir, si \(\mathbf{x}\) es un vector, \(\sigma(\mathbf{x}) = [\sigma(x_1), \sigma(x_2), \ldots, \sigma(x_n)]\).</p> <p>Recuerda, por otro lado, que las diferencias entre una función exponencial y una no exponencial (por ejemplo, cuadrática o lineal) está en el ritmo de crecimiento de la función. En el caso de una exponencial como \(f(x)=2^x\), si duplicamos el valor de la entrada, el valor de la salida se eleva al cuadrado: \(f(2x) = 2^{2x} = {(2^x)}^2\). En el caso de una función cuadrática como \(g(x)=x^2\), si duplicamos el valor de la entrada, el valor de la salida se multiplica por 4: \(g(2x)=(2x)^2 = 4x^2\). En el caso de una función lineal como \(h(x)=x\), si duplicamos el valor de la entrada, el valor de la salida también se duplica: \(h(2x)=2x\).</p> <h4 id="apartado-52">Apartado 5.2</h4> <p>El ejemplo de clasificación de sentimiento de esta sección es interesante porque muestra la técnica usada hasta hace unos años para esta tarea. Se supone aquí que una persona experta en el dominio ha definido las características (<em>features</em>) que ella considera que pueden ser importantes para decidir si una frase tiene connotaciones positivas o negativas. Estas características se calcularán para cada frase mediante otro programa antes de poder pasarlas por el regresor. Este es un proceso costoso, porque requiere expertos de cada dominio y porque el criterio de lo que es relevante o no puede ser subjetivo. El número de características en este caso solía estar alrededor de unas pocas decenas. En la actualidad, los modelos neuronales, como veremos, procesan los datos <em>en bruto</em> y aprenden las características más relevantes (en cantidades de cientos o miles de ellas), aunque en la mayoría de las ocasiones estas no tienen una interpretación lógica para los expertos.</p> <p>Por otra parte, la idea de normalización puede parecer ahora poco relevante, pero jugará un papel importante en el modelo del transformer para evitar que ciertos valores intermedios se hagan demasiado grandes o pequeños. Si miras la gráfica de la función sigmoide en el apartado anterior, verás que para valores de \(x\) muy grandes o muy pequeños no hay apenas diferencias en el valor de \(\sigma(x)\), por lo que la función no será sensible a pequeños cambios en el valor de \(x\). Además, en estas zonas la función es prácticamente plana, por lo que su derivada es muy pequeña lo que, como veremos más adelante, dificulta el entrenamiento.</p> <p>Por último, la idea de procesar varios datos de entrada a la vez es también muy importante, ya que permite reducir el tiempo de procesamiento. Puedes ver cómo empaquetando por filas una serie de vectores de entrada y con una simple multiplicación matricial seguida de la aplicación de la función sigmoide se obtiene el resultado de la clasificación de todos los vectores de entrada a la vez. Las GPUs están especializadas en poder realizar estas operaciones matriciales de forma muy eficiente, por lo que siempre intentaremos empaquetar los datos en los denominados <em>mini-batches</em> (mini-lotes, en español) para llenar la memoria de la GPU con la mayor cantidad de ellos y poder procesarlos en paralelo.</p> <p>Para que la operación de suma del sesgo sea consistente en tamaños, es necesario <em>estirar</em> el sesgo para obtener un vector \(b\) con el mismo tamaño que el número de muestras procesadas a la vez. Cuando trabajemos con PyTorch, veremos que esta operación se realiza automáticamente y que, gracias al mecanismo de <em>broadcasting</em>, no es necesario obtener explícitamente un vector con el valor del sesgo repetido varias veces y podremos sumar directamente el escalar o un tensor unidimensional de tamaño 1.</p> <h4 id="apartado-53">Apartado 5.3</h4> <p>La función softmax es el equivalente de la función sigmoide cuando se tiene que clasificar una muestra en más de dos clases. En este caso, la función recibe un vector de valores no normalizados (es decir, sin un rango concreto) y lo transforma en un vector de probabilidades de pertenencia a cada una de las clases. Al vector no normalizado se le denomina <em>logits</em> (logit es la función inversa de la función sigmoide). Observa que no podríamos haber normalizado los valores entre 0 y 1 dividiendo cada uno por la suma de todos ellos, porque hay valores negativos que anularían otros positivos. Podríamos haber considerado elevar cada valor del vector de entrada al cuadrado y dividirlo por la suma de todos los cuadrados, pero la función softmax destaca más las diferencias, como hemos comentado, y penaliza más los valores más alejados del máximo:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span> <span class="p">,</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1</span><span class="p">])</span>
<span class="n">squared</span> <span class="o">=</span> <span class="n">z</span><span class="o">*</span><span class="n">z</span> <span class="o">/</span> <span class="nf">sum</span><span class="p">(</span><span class="n">z</span><span class="o">*</span><span class="n">z</span><span class="p">)</span>
<span class="n">softmax</span><span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">squared</span><span class="p">,</span> <span class="n">softmax</span><span class="p">)</span>  
<span class="c1"># z =       [0.6000, 1.1000, -1.5000, 1.2000, 3.2000, -1.1000]
# squared = [0.0215, 0.0724,  0.1346, 0.0862, 0.6128,  0.0724]
# softmax = [0.0548, 0.0904,  0.0067, 0.0999, 0.7382,  0.0100]
</span></code></pre></div></div> <p>Observa que cuando en este apartado hacemos \(\hat{\mathbf{y}} = \mathrm{softmax} (\mathbf{W} \mathbf{x} + \mathbf{b})\), el vector \(\mathbf{x}\) corresponde a una única muestra, pero, a diferencia de apartados anteriores, \(\mathbf{W}\) es una matriz y \(\mathbf{b}\) es un vector con valores no necesariamente repetidos. En este caso, la matriz \(\mathbf{W}\) de forma \(K \times f\) transforma un vector columna de características de tamaño \(f\) (realmente, \(f \times 1\)) en un vector de logits de tamaño \(K\), donde \(K\) es el número de clases. Si cambiamos la forma de la matriz a \(f \times K\), entonces una operación equivalente se realizaría con \(\hat{\mathbf{y}} = \mathrm{softmax} (\mathbf{x} \mathbf{W} + \mathbf{b})\), donde ahora \(\mathbf{x}\) y \(\mathbf{b}\) son vectores fila (\(1 \times f\)) y no columna.</p> <p>Observa, asimismo, que en lugar de aplicar la operación a una única muestra (por ejemplo, las características de una sola frase), podemos hacerlo a un lote de estas, <em>apilándolas</em> por filas en una matriz \(\mathbf{X}\) y haciendo \(\hat{\mathbf{y}} = \mathrm{softmax} (\mathbf{X} \mathbf{W} + \mathbf{B})\) o apilándolas por columnas y haciendo \(\hat{\mathbf{y}} = \mathrm{softmax} (\mathbf{W} \mathbf{X} + \mathbf{B})\). En ambos casos, la matriz \(\mathbf{B}\) contendrá <em>repetido</em> \(m\) veces el vector de sesgos \(\mathbf{b}\). El resultado será un lote de \(m\) vectores de logits de tamaño \(K\), uno por cada muestra del lote.</p> <p>Cuando de ahora en adelante veas una ecuación de una parte de un modelo neuronal en la que se multiplica un lote de vectores por una matriz, puedes identificar que se trata de una transformación lineal que convierte cada uno de los vectores de entrada en otro vector normalmente de tamaño diferente. Recuerda bien esto cuando estudiemos el tema de las redes neuronales hacia adelante.</p> <p>En este apartado se introduce también el concepto de vector <em>one hot</em> (un vector donde todos los elementos son cero, excepto uno de ellos que vale uno), que usaremos con frecuencia para referirnos al vector con el que compararemos la salida de la red neuronal. Por ejemplo, si tenemos un problema de clasificación de imágenes de dígitos, el vector <em>one hot</em> que correspondería a la etiqueta del 3 sería \(\mathbf{y} = [0,0,0,1,0,0,0,0,0,0]\).</p> <h4 id="apartado-54">Apartado 5.4</h4> <p>Se avisa de que los dos próximos apartados se centran en la entropía cruzada y el descenso por gradiente para el caso de la regresión logística binaria y que después se retomará la regresión softmax.</p> <h4 id="apartado-55">Apartado 5.5</h4> <p>La ecuación \(p(y \vert x) = \hat{y}^y (1−\hat{y})^{1-y}\) es solo una forma compacta de escribir matemáticamente la idea de que si tenemos un dato correctamente etiquetado como \(y\) (donde \(y\) es cero o uno), la verosimilitud que el modelo da a este dato es \(\hat{y}\), si el dato está etiquetado como 1 y \(1−\hat{y}\) si está etiquetado como 0. Verosimilitud y probabilidad denotan algo muy similar a efectos prácticos, pero usaremos el término <em>verosimilitud</em> para referirnos a la probabilidad de una serie de datos cuando vamos asignando distintos valores a los parámetros (o pesos) del modelo; por otro lado, si los parámetros no son una variable aleatoria, sino que tienen un valor concreto, hablaremos de la <em>probabilidad</em> que tienen los datos dados los parámetros del modelo.</p> <p>Un aspecto básico del entrenamiento de redes neuronales es el principio de estimación por máxima verosimilitud. La explicación del capítulo sobre este método puede complementarse con este <a href="https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/19/01-Maximum-likelihood-estimation.html" rel="external nofollow noopener" target="_blank">breve tutorial</a> <a href="https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/19/01-Maximum-likelihood-estimation.html" rel="external nofollow noopener" target="_blank"><i class="fas fa-file"></i></a>. La idea básica es ir <em>probando</em> con diferentes valores de los parámetros intentando encontrar los que maximizan la verosimilitud de los datos. En el caso de la regresión logística, esto se traduce en encontrar los valores de los pesos \(\mathbf{w}\) (o bien \(\mathbf{W}\) en el caso de la regresión multinomial) y del sesgo \(b\) (o los sesgos \(\mathbf{b}\)) que maximizan la probabilidad de que los datos etiquetados como 1 tengan una verosimilitud alta de ser 1 y los datos etiquetados como 0 tengan una verosimilitud baja de ser 1.</p> <p>Aunque en algún momento del capítulo se calcula el valor concreto de la función de pérdida \(L_{CE}(\hat{y},y)\) para un par de datos concretos, nuestro principal interés estará en la forma analítica de la ecuación (5.23), ya que, como se ve en el siguiente apartado, es la que usaremos para calcular el gradiente de la función de pérdida con respecto a los parámetros del modelo y, por tanto, para actualizarlos en cada paso de entrenamiento. No obstante, la media de la función de error sobre un conjunto de datos (bien los datos de entrenamiento, bien los de validación) en forma de un número concreto (0.564, por ejemplo) nos será útil durante el entrenamiento para comprobar si el modelo está mejorando o no sus predicciones sobre el conjunto de entrenamiento.</p> <p>Aunque pueda parecer contraintuitivo, con el entrenamiento no buscamos que el valor de la entropía cruzada sobre los datos de entrenamiento llegue a cero. Valores muy bajos de la función de error son un signo de lo que se conoce como <em>sobreaprendizaje</em> (<em>overfitting</em>), que suele implicar que cuando el sistema es evaluado sobre datos nuevos, no es capaz de generalizar bien. Para evitarlo, nos guardaremos habitualmente una parte de los datos para evaluar el modelo sobre ellos y comprobar si hay una mejora sobre datos independientes. A este conjunto reducido de datos se le conoce como <em>conjunto de validación</em> (<em>validation set</em> o <em>development set</em>). Cada cierto número de pasos de entrenamiento, el modelo se evaluará sobre el conjunto de validación y se comprobará si el valor de la entropía cruzada sobre este conjunto ha mejorado o no. Si no ha mejorado, se parará el entrenamiento y se usará el modelo que mejor se haya comportado sobre el conjunto de validación. Normalmente, se usa un término de <em>paciencia</em> (<em>patience</em>) que regula el número de pasos de entrenamiento que se avanza sin que el modelo mejore sobre el conjunto de validación antes de detener el entrenamiento. A la hora de evaluar el desempeño sobre el conjunto de validación, no estamos obligados a usar la entropía cruzada, sino que podemos usar cualquier otra función de pérdida que nos interese. Así, si estamos resolviendo un problema de clasificación de imágenes, podemos usar la precisión (<em>accuracy</em>) como medida de desempeño. Además de los conjuntos de datos anteriores (para entrenamiento y validación), también se suele usar un conjunto de datos de prueba (<em>test set</em>) para evaluar el modelo final sobre datos que no han sido vistos por el modelo durante su entrenamiento.</p> <p>La discusión sobre la entropía cruzada (<em>cross-entropy</em>) se puede extender un poco para ver de dónde viene esta función y por qué minimizarla es equivalente a maximizar la verosimilitud. Más <a href="#entrop%C3%ADa">abajo</a> tienes una pequeña explicación de este tema.</p> <p>Los logaritmos van a aparecer con cierta frecuencia en tu aprendizaje sobre redes neuronales, por lo que es conveniente recordar algunas de sus propiedades:</p> <ul> <li>Logaritmo del producto: \(\log(xy) = \log(x) + \log(y)\)</li> <li>Logaritmo de la división: \(\log(x/y) = \log(x) - \log(y)\)</li> <li>Logaritmo de la exponenciación: \(\log(x^a) = a\log(x)\), donde \(a\) es una constante</li> <li>Logaritmo de uno: \(\log(1) = 0\)</li> </ul> <p>En particular, el logaritmo de un valor entre cero y uno es negativo, por lo que verás que cuando se hable del logaritmo de la probabilidad de un dato (a veces se denota por <em>logprob</em>), este tendrá valores como -4,321 o -12,678. Una probabilidad (logarítmica) de -4,321 es mayor que una de -12,678 y representará, por tanto, un evento más probable.</p> <h4 id="apartado-56">Apartado 5.6</h4> <p>Para recordar fácilmente cómo afecta la derivada a la actualización de los pesos considera, para simplificar, que la función de error adopta la forma \(x^2\) y observa en la siguiente gráfica cómo cuando el gradiente es negativo (en el punto con la marca de la estrella) es necesario incrementar el peso para reducir el error, mientras que cuando el gradiente es positivo (en el punto con la marca del círculo) es necesario reducir el peso para reducir el error. En la gráfica se muestra también la derivada de la función de error, que es \(2x\).</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/me2/assets/img/transformers/derivativex2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/me2/assets/img/transformers/derivativex2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/me2/assets/img/transformers/derivativex2-1400.webp"></source> <img src="/me2/assets/img/transformers/derivativex2.png" class="img-fluid rounded z-depth-1" width="512px" height="auto" title="derivative of x^2" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>La gráfica anterior ha sido generada con el siguiente código en Python que usa la librería Matplotlib. Estudia qué hace cada instrucción del programa.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">squares</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span>
<span class="n">derivative</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">squares</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="o">-</span><span class="mi">17</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="sa">r</span><span class="s">'$x^2$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="nf">squares</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">),</span> <span class="n">marker</span><span class="o">=</span><span class="s">"*"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"blue"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">arrow</span><span class="p">(</span><span class="o">-</span><span class="mi">14</span><span class="p">,</span> <span class="nf">squares</span><span class="p">(</span><span class="mi">15</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"green"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="nf">squares</span><span class="p">(</span><span class="mi">18</span><span class="p">),</span> <span class="n">marker</span><span class="o">=</span><span class="s">"o"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"blue"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">arrow</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="nf">squares</span><span class="p">(</span><span class="mi">18</span><span class="p">),</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"green"</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">derivative</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">72</span><span class="p">,</span> <span class="sa">r</span><span class="s">'$2x$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s">'$w$'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="s">"derivativex2.png"</span><span class="p">)</span>
</code></pre></div></div> <h4 id="apartado-57">Apartado 5.7</h4> <p>Puedes saltar este apartado sobre la regularización, ya que no es fundamental en estos momentos para entender el funcionamiento básico de las redes neuronales.</p> <h4 id="apartado-58">Apartado 5.8</h4> <p>Cuando se usa la entropía cruzada como función de error en la regresión multinomial, su forma es muy sencilla, ya que es igual al logaritmo de la probabilidad emitida por el modelo para la clase correcta. No obstante, la complejidad de la derivada dependerá de la complejidad de todo el modelo subyacente. La entropía cruzada es en este caso:</p> \[L_{CE}(\hat{y},y) = -\log(\hat{y}_i)\] <p>donde \(\hat{y}_i\) es la probabilidad de que la entrada pertenezca a la clase \(i\), esto es, a la clase correcta. Observa que no se están ignorando las probabilidades de las otras clases, ya que intentar maximizar la probabilidad de la clase correcta implica minimizar la probabilidad de las otras clases.</p> <p>En el caso de la regresión logística binaria, la función de error es la entropía cruzada binaria, que ya vimos que adopta la siguiente forma:</p> \[L_{CE}(\hat{y},y) = -y\log(\hat{y}) - (1-y)\log(1-\hat{y})\] <h4 id="apartado-59">Apartado 5.9</h4> <p>Puedes saltar este apartado.</p> <h4 id="apartado-510">Apartado 5.10</h4> <p>Se calcula aquí paso a paso el gradiente de la entropía cruzada binaria respecto a cada uno de los parámetros (pesos y sesgo) del regresor logístico binario. Estas son las reglas de derivación que se necesitan para derivar la mayor parte de las funciones de error que se usan en redes neuronales:</p> <ul> <li>Derivada con un exponente: \(\frac{d}{dx}(x^a) = a x^{a-1}\), donde \(a\) es una constante</li> <li>Derivada con el producto de una constante: \(\frac{d}{dx}(cx) = c\), donde \(c\) es una constante</li> <li>Derivada de una constante: \(\frac{d}{dx}(c) = 0\)</li> <li>Derivada de la suma: \(\frac{d}{dx}(x+y) = \frac{d}{dx}(x) + \frac{d}{dx}(y)\)</li> <li>Derivada del logaritmo: \(\frac{d}{dx}(\log(x)) = \frac{1}{x}\)</li> <li>Derivada del producto: \(\frac{d}{dx}(xy) = y\frac{d}{dx}(x) + x\frac{d}{dx}(y)\)</li> </ul> <p>Dado que la función de error será una función compuesta de múltiples funciones, la regla de la cadena nos será de suma utilidad:</p> \[\displaystyle \frac{\displaystyle d f(g(x))}{\displaystyle dx} = f'(g(x))\cdot g'(x) = \frac{\displaystyle d f}{\displaystyle dg}\cdot \frac{\displaystyle d g}{\displaystyle dx}\] <p>donde \(f'\) y \(g'\) representan las derivadas de \(f\) y \(g\) respectivamente. Por ejemplo, si \(f(x) = x^2\) y \(g(x) = 2x\), entonces \(f(g(x)) = (2x)^2 = 4x^2\) y aplicando la regla de la cadena:</p> \[\displaystyle \frac{\displaystyle d f(g(x))}{\displaystyle dx} = f'(g(x))\cdot g'(x) = \frac{\displaystyle d ((2x)^2)}{\displaystyle d 2x}\cdot \frac{\displaystyle d 2x}{\displaystyle dx} = 4x\cdot 2 = 8x\] <p>Sería interesante que calcularas la derivada de la entropía cruzada binaria respecto al umbral (en el libro se muestra la derivada respecto a los pesos) y que te animaras a calcular también el gradiente para el caso de la regresión logística multinomial.</p> <h2 id="regresores-implementados-en-pytorch">Regresores implementados en PyTorch</h2> <p>Estas son dos implementaciones en PyTorch de los regresores que hemos estudiado en unas pocas decenas de líneas de código (normalmente menos de 100). Asegúrate de que terminas entendiendo el código lo suficiente como para sentirte con ánimo de poder modificarlo para adaptarlo a otras necesidades. Repasa antes cómo puedes <a href="pytorch#depuraci%C3%B3n">depurar</a> programas escritos en Python.</p> <ul> <li>Un <a href="https://github.com/jaspock/me/blob/master/assets/code/transformers/logistic-regressor.py" rel="external nofollow noopener" target="_blank">regresor logístico</a> <a href="https://github.com/jaspock/me/blob/master/assets/code/transformers/logistic-regressor.py" rel="external nofollow noopener" target="_blank"><i class="fas fa-file"></i></a> que clasifica muestras bidimensionales sintéticas en dos clases. Se usan solo los elementos más básicos de PyTorch para poder tener una implementación lo más detallada posible. Como ejercicio, puedes hacer una traza y analizar qué tamaños tienen los tensores. Puedes jugar también con el número de pasos de entrenamiento y la tasa de aprendizaje para ver cómo evoluciona el entrenamiento. Explora diversas posiciones de los centros de las clases y de la dispersión de los datos alrededor de estos y observa cómo cambia la frontera de decisión. Elimina el sesgo (<em>bias</em>) de las ecuaciones y observa cómo se restringe la forma de la frontera de decisión al obligar a esta a pasar por el origen de coordenadas.</li> <li>Un <a href="https://github.com/jaspock/me/blob/master/assets/code/transformers/softmax-regressor.py" rel="external nofollow noopener" target="_blank">regresor softmax para clasificar imágenes de dígitos</a> <a href="https://github.com/jaspock/me/blob/master/assets/code/transformers/softmax-regressor.py" rel="external nofollow noopener" target="_blank"><i class="fas fa-file"></i></a>. Las imágenes y etiquetas de los dígitos se toman de un conjunto de datos muy conocido llamado MNIST. Como ejercicio, puedes simplificar este código para que realice una tarea de clasificación de sentimiento sobre un conjunto de datos sintéticos muy pequeño que se defina explícitamente en el propio programa; puedes inspirarte en el código de los siguientes ejemplos para ello.</li> </ul> <p>Si no lo has hecho ya, puedes empezar a aprender Python y PyTorch siguiendo el <a href="../python">capítulo</a> correspondiente de esta serie.</p> <p><strong>Actividad práctica.</strong> Utiliza las herramientas de depuración como se explicaron <a href="pytorch.html#depuraci%C3%B3n">aquí</a> para explorar paso a paso el código de los regresores. Analiza el valor y tipo de las variables, así como la forma de cada tensor y asegúrate de que entiendes qué representa cada dimensión.</p> <h2 id="broadcasting-en-pytorch">Broadcasting en PyTorch</h2> <p>Observa que en la ecuación 5.12 el vector \(\mathbf{b}\) se obtiene copiando repetidamente el valor escalar \(b\). Cuando ecuaciones como esta se implementan en PyTorch, no es necesario hacer esta copia explícita gracias al mecanismo de <em>broadcasting</em> que se activa automáticamente en algunas ocasiones cuando se combinan tensores de tamaños en principio incompatibles:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span> 
<span class="n">b</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span></code></pre></figure> <h2 id="entropía">Entropía</h2> <p>Considera el caso en que el que un suceso \(x\) puede ocurrir con una probabilidad \(p_x\) modelada mediante una determinada distribución de probabilidad $p$. Supongamos que queremos calcular la cantidad de información \(I(x)\) de dicho suceso o, en palabras más sencillas, la <em>sorpresa</em> que nos produciría que este suceso tuviera lugar. Como primera aproximación, es fácil ver que la inversa de la probabilidad, \(1/p_x\), da un valor mayor cuando la probabilidad es pequeña (nos sorprende más que ocurra algo improbable) y un valor menor cuando la probabilidad es mayor (nos sorprende poco que ocurra algo muy probable).</p> <p>Además, parece lógico que la cantidad de información de un suceso seguro (con probabilidad 1) sea 0. Para conseguirlo, dado que el logaritmo es una función monótona creciente, podemos aplicar el logaritmo al cociente anterior sin que cambie el orden relativo de dos sucesos con diferentes probabilidades:</p> \[I(x) = \log\left(\frac{1}{p_x}\right) = - \log (p_x)\] <p>La cantidad de información se mide en bits si el logaritmo es en base 2 y en <em>nats</em> si es en base \(e\). La entropía \(H\) de la distribución de probabilidad es una medida de la información promedio de todos los posibles sucesos. Para obtenerla basta con ponderar la información de cada suceso por su probabilidad y sumar sobre todos los sucesos:</p> \[H(p) = - \sum_{x} p_x \log(p_x)\] <p>Comprueba que la entropía es máxima si todos los sucesos son equiprobables. La entropía cruzada entre dos distribuciones de probabilidad mide la sorpresa que nos provoca un determinado suceso si usamos una distribución de probabilidad $q$ alternativa a la probabilidad real $p$:</p> \[H(p,q) = - \sum_{x} p_x \log(q_x)\] <p>Puedes ver, por lo tanto, que la fórmula (5.21) del libro coincide con la ecuación anterior: maximizar la verosimilitud respecto a los parámetros del modelo es equivalente a minimizar la entropía cruzada \(H(y,\hat{y})\).</p> <h2 id="ejercicios-de-repaso">Ejercicios de repaso</h2> <p>Estos ejercicios te permitirán repasar los conceptos más importantes de este capítulo.</p> <ol> <li>La disposición de los elementos en matrices y vectores puede ser diferente a la utilizada en la sección 5.2.3. Lo realmente importante es que se realice el productor escalar de cada una de las \(m\) muestras con el vector de pesos \(\mathbf{w}\). Indica qué tamaños deberían tener las matrices y vectores si en lugar de una ecuación como la (5.14), usamos una de la forma \(\mathbf{y} = \mathbf{w} \mathbf{X} + \mathbf{b}\).</li> <li>Calcula la derivada de la función de coste respecto al umbral \(b\). Si te basas en la derivada de la función de coste respecto a los pesos \(w\), que está calculada en el libro, llegarás rápido a la solución.</li> <li>Tras entrenar un regresor logístico, le aplicamos una entrada \(\mathbf{x}\) y calculamos la derivada \(\partial \hat{y} / \partial \mathbf{x}_i\) para un cierto \(i\). ¿Qué mide esta derivada? Piensa en el concepto básico de la derivada y en cómo mide la <em>sensibilidad</em> del valor de un función respecto a un cambio en una de sus variables.</li> </ol> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Juan Antonio Pérez-Ortiz. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/me2/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/me2/assets/js/zoom.js"></script> <script defer src="/me2/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>